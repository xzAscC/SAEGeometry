{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/huohu/Documents/code/SAEGeometry/config/saegeometry-1tp4usyN-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.24it/s]\n",
      "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import sae_lens\n",
    "import torch\n",
    "import jaxtyping\n",
    "import random\n",
    "import datasets\n",
    "import plotly.colors as pc\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "def obtain_data() -> (\n",
    "    Tuple[List[sae_lens.SAE], torch.nn.Module, torch.utils.data.Dataset]\n",
    "):\n",
    "    \"\"\"\n",
    "    load sae, model and dataset\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    layers = 6\n",
    "    saes = []\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    model_name = \"pythia-70m-deduped\"\n",
    "    for layer in tqdm(range(layers)):\n",
    "        sae_id = f\"blocks.{layer}.hook_resid_post\"\n",
    "        saes.append(\n",
    "            sae_lens.SAE.from_pretrained(release=release, sae_id=sae_id, device=device)[\n",
    "                0\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    model = sae_lens.HookedSAETransformer.from_pretrained(model_name)\n",
    "    ds = datasets.load_dataset(\"Salesforce/wikitext\", \"wikitext-2-raw-v1\")[\"train\"]\n",
    "\n",
    "    return saes, model, ds\n",
    "\n",
    "saes, model, ds = obtain_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36529/93926725.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  code_acts = torch.load(\"../res/acts/BAAI-TACO-pythia70m-res-all6-acts.pt\")\n",
      "/tmp/ipykernel_36529/93926725.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  math_acts = torch.load(\"../res/acts/math-pythia70m-res-all6-acts.pt\")\n",
      "/tmp/ipykernel_36529/93926725.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  wiki_acts = torch.load(\"../res/acts/wiki-pythia70m-res-all6-acts.pt\")\n"
     ]
    }
   ],
   "source": [
    "code_acts = torch.load(\"../res/acts/BAAI-TACO-pythia70m-res-all6-acts.pt\")\n",
    "math_acts = torch.load(\"../res/acts/math-pythia70m-res-all6-acts.pt\")\n",
    "wiki_acts = torch.load(\"../res/acts/wiki-pythia70m-res-all6-acts.pt\")\n",
    "\n",
    "top_num = 325\n",
    "top_index_code = torch.topk(code_acts, top_num).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36718"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n",
      "100%|██████████| 10/10 [00:14<00:00,  1.44s/it]\n",
      "100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n",
      "100%|██████████| 10/10 [00:14<00:00,  1.42s/it]\n",
      "100%|██████████| 10/10 [00:13<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "nz_all = []\n",
    "doc_len = 0\n",
    "freq_mean_global = 0\n",
    "layers = 6\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "freqs = torch.zeros(saes[0].cfg.d_sae).to(device)\n",
    "abl_layer = 0\n",
    "abl_times = 10\n",
    "for layer in range(layers-1):\n",
    "    nz_freqs = []\n",
    "    abl_layer = layer\n",
    "    for idx in tqdm(range(abl_times)):\n",
    "        saes2 = copy.deepcopy(saes)\n",
    "        with torch.no_grad():\n",
    "            abl_num = 29\n",
    "            list(map(lambda idy: saes2[abl_layer].W_dec[idy, :].zero_(), top_index_code[0][abl_num*idx:abl_num*(idx+1)]))\n",
    "        ds_ratio = 1e-3\n",
    "        length_ds = int(len(ds) * ds_ratio)\n",
    "        for idx in range(length_ds):\n",
    "            # loop begin, fuck indent\n",
    "            example = ds[idx]\n",
    "            tokens = model.to_tokens([example[\"text\"]], prepend_bos=True)\n",
    "            _, cache1 = model.run_with_cache_with_saes(tokens, saes=saes, use_error_term=False)\n",
    "            model.reset_saes()\n",
    "            _, cache2 = model.run_with_cache_with_saes(tokens, saes=saes2, use_error_term=False)\n",
    "            local_doc_len = cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "            freq = torch.zeros_like(freqs)\n",
    "            \n",
    "            prompt2 = f\"blocks.{abl_layer + 1}.hook_resid_post.hook_sae_acts_post\"\n",
    "            freq = (((cache1[prompt2] > 1e-3) + 0 + cache2[prompt2] > 1e-3)==1)[0].sum(\n",
    "                0\n",
    "            ) / local_doc_len\n",
    "            # freq[layer] = (cache[prompt2] > 1e-3)[0].sum(0) / local_doc_len\n",
    "            new_doc_len = doc_len + local_doc_len\n",
    "            if idx == 0:\n",
    "                freq_mean_global = freq\n",
    "            else:\n",
    "                freq_mean_global = (\n",
    "                    freq_mean_global * doc_len / new_doc_len\n",
    "                    + freq * local_doc_len / new_doc_len\n",
    "                )\n",
    "            doc_len = new_doc_len\n",
    "        nz_freqs.append(freq_mean_global)\n",
    "    nz_all.append(nz_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common iou: (310,) abl_layer: 0 influence freq: torch.Size([8160])\n",
      "common iou: (311,) abl_layer: 0 influence freq: torch.Size([8320])\n",
      "common iou: (311,) abl_layer: 0 influence freq: torch.Size([8147])\n",
      "common iou: (311,) abl_layer: 0 influence freq: torch.Size([8224])\n",
      "common iou: (312,) abl_layer: 0 influence freq: torch.Size([8123])\n",
      "common iou: (310,) abl_layer: 0 influence freq: torch.Size([8171])\n",
      "common iou: (311,) abl_layer: 0 influence freq: torch.Size([8158])\n",
      "common iou: (312,) abl_layer: 0 influence freq: torch.Size([8146])\n",
      "common iou: (311,) abl_layer: 0 influence freq: torch.Size([8154])\n",
      "common iou: (311,) abl_layer: 0 influence freq: torch.Size([8124])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7014])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7018])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7014])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7018])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7015])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7043])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7017])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7029])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7015])\n",
      "common iou: (322,) abl_layer: 1 influence freq: torch.Size([7015])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([8006])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([7960])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([7971])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([8008])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([8048])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([7960])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([7976])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([7965])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([7980])\n",
      "common iou: (319,) abl_layer: 2 influence freq: torch.Size([7958])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11017])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11016])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11032])\n",
      "common iou: (317,) abl_layer: 3 influence freq: torch.Size([11032])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11021])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11042])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11040])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11015])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11037])\n",
      "common iou: (316,) abl_layer: 3 influence freq: torch.Size([11117])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13850])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13848])\n",
      "common iou: (311,) abl_layer: 4 influence freq: torch.Size([13875])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13844])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13853])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13845])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13858])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13845])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13849])\n",
      "common iou: (310,) abl_layer: 4 influence freq: torch.Size([13886])\n"
     ]
    }
   ],
   "source": [
    "res_ = []\n",
    "for layer in range(layers-1):\n",
    "    for idx in range(len(nz_freqs)):\n",
    "        res = np.intersect1d(top_index_code[layer+1].cpu().numpy(), nz_all[layer][idx].nonzero().view(-1).cpu().numpy())\n",
    "        print(f'common iou: {res.shape} abl_layer: {layer} influence freq: {nz_all[layer][idx].nonzero().view(-1).shape}')\n",
    "# last_iou = res_[0]\n",
    "# for idx in range(len(res_) - 1):\n",
    "#     iou = np.intersect1d(last_iou, res_[idx])\n",
    "#     last_iou = iou\n",
    "#     print(f\"iou with last abl: {iou.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81,)\n",
      "(81,)\n",
      "(81,)\n",
      "(81,)\n",
      "(81,)\n",
      "(81,)\n",
      "(81,)\n",
      "(81,)\n",
      "(81,)\n"
     ]
    }
   ],
   "source": [
    "last_iou = res_[0]\n",
    "for idx in range(len(res_) - 1):\n",
    "    iou = np.intersect1d(last_iou, res_[idx])\n",
    "    last_iou = iou\n",
    "    print(iou.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  129   387   492   813  1130  2521  2987  3362  3641  3664  4078  4445\n",
      "  5289  5325  5355  5516  5884  5958  6589  6900  7188  7262  7308  7483\n",
      "  7700  8038  8235  8527  8821  9801 10122 10155 10235 10491 12169 12405\n",
      " 12422 12930 13874 14165 14264 14485 15114 15376 15433 16401 17241 17278\n",
      " 18295 18706 18920 19135 20697 20895 21162 21401 21962 22079 22170 23497\n",
      " 23645 24241 24972 26296 26476 26619 26906 27266 27452 28531 29009 29251\n",
      " 29987 30263 30939 31570 31698 31724 31883 31885 32636 32674]\n"
     ]
    }
   ],
   "source": [
    "print(res_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saegeometry-1tp4usyN-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
