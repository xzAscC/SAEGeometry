{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch gradient enabled: True\n"
     ]
    }
   ],
   "source": [
    "grad_enabled = torch.is_grad_enabled()\n",
    "print(f\"Torch gradient enabled: {grad_enabled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/huohu/Documents/code/SAEGeometry/config/saegeometry-1tp4usyN-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sae_lens\n",
    "import torch\n",
    "import datasets\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "def fetch_sae_and_model(\n",
    "    sae_name: str,\n",
    ") -> Tuple[List[sae_lens.SAE], sae_lens.HookedSAETransformer]:\n",
    "    \"\"\" fetch the specified SAE and model given the SAE name\n",
    "\n",
    "    Args:\n",
    "        sae_name (str): the name of the SAE\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[sae_lens.SAE], sae_lens.HookedSAETransformer]: the SAEs and the model\n",
    "    \"\"\"    \n",
    "    if sae_name == \"llama3.1-8b\":\n",
    "        model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "        layers = 32\n",
    "        release = \"llama_scope_lxr_8x\"\n",
    "    elif sae_name == \"pythia-70m-deduped\":\n",
    "        model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "        layers = 6\n",
    "        release = \"pythia-70m-deduped-res-sm\"\n",
    "    elif sae_name == \"gemma-2-2b\":\n",
    "        model_name = \"gemma-2-2b\"\n",
    "        layers = 26\n",
    "        release = \"gemma-scope-2b-pt-res-canonical\"\n",
    "    saes = fetch_sae(release, layers)\n",
    "    model = fetch_model(model_name)\n",
    "    return saes, model\n",
    "\n",
    "\n",
    "def fetch_sae(release: str, layers: int) -> sae_lens.SAE:\n",
    "    saes = []\n",
    "    for layer in tqdm(range(layers)):\n",
    "        if release == \"gemma-scope-2b-pt-res-canonical\":\n",
    "            sae_id = f\"layer_{layer}/width_16k/canonical\"\n",
    "        elif release == \"llama_scope_lxr_8x\":\n",
    "            sae_id = f\"l{layer}r_8x\"\n",
    "        elif release == \"pythia-70m-deduped-res-sm\":\n",
    "            sae_id = f\"blocks.{layer}.hook_resid_post\"\n",
    "        sae = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "        sae.to(dtype=torch.bfloat16)\n",
    "        saes.append(sae)\n",
    "    return saes\n",
    "\n",
    "\n",
    "def fetch_model(model_name: str) -> sae_lens.HookedSAETransformer:\n",
    "    model = sae_lens.HookedSAETransformer.from_pretrained(\n",
    "        model_name, dtype=torch.bfloat16\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n",
      "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n",
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "saes, model = fetch_sae_and_model(\"pythia-70m-deduped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"Salesforce/wikitext\", \"wikitext-2-raw-v1\")[\n",
    "                \"train\"\n",
    "            ]\n",
    "text = \"text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 36\n"
     ]
    }
   ],
   "source": [
    "ds_ratio = 1e-3\n",
    "dataset_length = int(len(dataset) * ds_ratio)\n",
    "print(f\"Dataset length: {dataset_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 6.11964750289917\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 6.11964750289917\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 6.041692211626593e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 6.041692211626593e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.6854300547981642e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.23993034660816193\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.23993034660816193\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.9389699106042695e-15\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.9389699106042695e-15\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 7.325880493497261e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.0002373579773120582\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.00023735793365631253\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 3.4758309333979514e-16\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 3.4758309333979514e-16\n",
      "Key: blocks.0.hook_resid_post.hook_sae_output, diff: 3.898777512670277e-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 2.27205228805542\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 2.27205228805542\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.3266534951757863e-13\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.3266534951757863e-13\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.423267241437408e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.8473105430603027\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.8473105430603027\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.249702754203396e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.249702754203396e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 3.2475234727400402e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 5.611774921417236\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 5.611774921417236\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.869266849396708e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.869266849396708e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 5.92818412157377e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.8169901371002197\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.8169901371002197\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 4.137549948924485e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 4.137549948924485e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 8.52615572003064e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 2.3215298652648926\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 2.3215298652648926\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.10092394056869e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.10092394056869e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 5.200932220973068e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:03<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.45195791125297546\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.45195791125297546\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.6388720418193843e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.6388720418193843e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.583527780882053e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 48896.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 48896.0\n",
      "Key: blocks.4.attn.hook_q, diff: 16128.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 16128.0\n",
      "Key: blocks.3.attn.hook_q, diff: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idy in range(10):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # random_indices = torch.randint(0, 32577, (900,))\n",
    "    # list(map(lambda idx: sae2.W_dec[idx, :].zero_(), random_indices))\n",
    "    sae2.W_dec[idy*10:(idy+1)*10, :].zero_()\n",
    "    cache = {}\n",
    "    for idx in tqdm(range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    for key, _ in top_10_keys:\n",
    "        print(f\"Key: {key}, diff: {cache[key]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 48896.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 48896.0\n",
      "Key: blocks.4.attn.hook_q, diff: 16128.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 16128.0\n",
      "Key: blocks.3.attn.hook_q, diff: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idy in range(1):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # random_indices = torch.randint(0, 32577, (900,))\n",
    "    # list(map(lambda idx: sae2.W_dec[idx, :].zero_(), random_indices))\n",
    "    sae2.W_dec[0:100, :].zero_()\n",
    "    cache = {}\n",
    "    for idx in tqdm(range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    for key, _ in top_10_keys:\n",
    "        print(f\"Key: {key}, diff: {cache[key]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "不重要的消融只在局部有微小的影响\n",
    "重要的消融会直接影响最后几层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 9.481203079223633\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 9.481203079223633\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.9212249521317892e-13\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.9212249521317892e-13\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 4.2826673603930596e-14\n",
      "Key: blocks.2.ln2.hook_normalized, diff: 4.2826673603930596e-14\n",
      "Key: blocks.0.hook_resid_post.hook_sae_output, diff: 1.9265278188387337e-14\n",
      "Key: blocks.1.hook_resid_pre, diff: 1.9265278188387337e-14\n",
      "Key: blocks.3.ln1.hook_normalized, diff: 9.005632272351093e-15\n",
      "Key: blocks.3.ln2.hook_normalized, diff: 9.005632272351093e-15\n",
      "Key: blocks.1.hook_resid_post, diff: 7.984138490049666e-15\n",
      "Key: blocks.2.hook_resid_pre, diff: 7.984138490049666e-15\n",
      "Key: blocks.2.hook_resid_post, diff: 2.966923691929556e-15\n",
      "Key: blocks.3.hook_resid_pre, diff: 2.966923691929556e-15\n",
      "Key: blocks.4.ln1.hook_normalized, diff: 2.155272157915015e-15\n",
      "Key: blocks.4.ln2.hook_normalized, diff: 2.155272157915015e-15\n",
      "Key: blocks.3.hook_resid_post, diff: 9.650119313126156e-16\n",
      "Key: blocks.4.hook_resid_pre, diff: 9.650119313126156e-16\n",
      "Key: blocks.5.ln1.hook_normalized, diff: 8.042452896819862e-16\n",
      "Key: blocks.5.ln2.hook_normalized, diff: 8.042452896819862e-16\n",
      "Key: blocks.4.hook_resid_post, diff: 4.3044353553957544e-16\n",
      "Key: blocks.5.hook_resid_pre, diff: 4.3044353553957544e-16\n",
      "Key: hook_embed, diff: 0.0\n",
      "Key: blocks.0.hook_resid_pre, diff: 0.0\n",
      "Key: blocks.0.ln1.hook_scale, diff: 0.0\n",
      "Key: blocks.0.ln1.hook_normalized, diff: 0.0\n",
      "Key: blocks.0.attn.hook_q, diff: 0.0\n",
      "Key: blocks.0.attn.hook_k, diff: 0.0\n",
      "Key: blocks.0.attn.hook_v, diff: 0.0\n",
      "Key: blocks.0.attn.hook_rot_q, diff: 0.0\n",
      "Key: blocks.0.attn.hook_rot_k, diff: 0.0\n",
      "Key: blocks.0.attn.hook_attn_scores, diff: 0.0\n",
      "Key: blocks.0.attn.hook_pattern, diff: 0.0\n",
      "Key: blocks.0.attn.hook_z, diff: 0.0\n",
      "Key: blocks.0.hook_attn_out, diff: 0.0\n",
      "Key: blocks.0.ln2.hook_scale, diff: 0.0\n",
      "Key: blocks.0.ln2.hook_normalized, diff: 0.0\n",
      "Key: blocks.0.mlp.hook_pre, diff: 0.0\n",
      "Key: blocks.0.mlp.hook_post, diff: 0.0\n",
      "Key: blocks.0.hook_mlp_out, diff: 0.0\n",
      "Key: blocks.0.hook_resid_post.hook_sae_input, diff: 0.0\n",
      "Key: blocks.0.hook_resid_post.hook_sae_acts_pre, diff: 0.0\n",
      "Key: blocks.0.hook_resid_post.hook_sae_acts_post, diff: 0.0\n",
      "Key: blocks.1.ln1.hook_scale, diff: 0.0\n",
      "Key: blocks.1.attn.hook_q, diff: 0.0\n",
      "Key: blocks.1.attn.hook_k, diff: 0.0\n",
      "Key: blocks.1.attn.hook_v, diff: 0.0\n",
      "Key: blocks.1.attn.hook_rot_q, diff: 0.0\n",
      "Key: blocks.1.attn.hook_rot_k, diff: 0.0\n",
      "Key: blocks.1.attn.hook_attn_scores, diff: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idy in range(1):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # random_indices = torch.randint(0, 32577, (900,))\n",
    "    # list(map(lambda idx: sae2.W_dec[idx, :].zero_(), random_indices))\n",
    "    sae2.W_dec[0:50, :].zero_()\n",
    "    cache = {}\n",
    "    for idx in tqdm(range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:50]\n",
    "    for key, _ in top_10_keys:\n",
    "        print(f\"Key: {key}, diff: {cache[key]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:30<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "high_diff_keys = []\n",
    "low_diff_keys = []\n",
    "for idy in tqdm(range(30)):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # random_indices = torch.randint(0, 32577, (900,))\n",
    "    # list(map(lambda idx: sae2.W_dec[idx, :].zero_(), random_indices))\n",
    "    sae2.W_dec[idy*20:(idy+1)*20, :].zero_()\n",
    "    cache = {}\n",
    "    for idx in (range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "            \n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    flag = False\n",
    "    for key, _ in top_10_keys:\n",
    "        if key.startswith(\"blocks.5\"):\n",
    "            high_diff_keys.append(idy)\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        low_diff_keys.append(idy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_762/3380867524.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  acts = torch.load(\"../res/acts/pythia_freqs_code.pt\")\n"
     ]
    }
   ],
   "source": [
    "acts = torch.load(\"../res/acts/pythia_freqs_code.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High diff keys: [4, 24]\n",
      "Low diff keys: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(f\"High diff keys: {high_diff_keys}\")\n",
    "print(f\"Low diff keys: {low_diff_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 4, freq: (80, 100), freq sum: 0.007100939285010099\n",
      "Key: 24, freq: (480, 500), freq sum: 0.18820755183696747\n"
     ]
    }
   ],
   "source": [
    "for idy in high_diff_keys:\n",
    "    print(f\"Key: {idy}, freq: {idy*20,(idy+1)*20}, freq sum: {acts[0][idy*20:(idy+1)*20].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 0, freq: (0, 20), freq sum: 0.014347216114401817\n",
      "Key: 1, freq: (20, 40), freq sum: 0.06822924315929413\n",
      "Key: 2, freq: (40, 60), freq sum: 0.0171254500746727\n",
      "Key: 3, freq: (60, 80), freq sum: 0.10168902575969696\n",
      "Key: 5, freq: (100, 120), freq sum: 0.004115692339837551\n",
      "Key: 6, freq: (120, 140), freq sum: 0.11486919969320297\n",
      "Key: 7, freq: (140, 160), freq sum: 0.009952389635145664\n",
      "Key: 8, freq: (160, 180), freq sum: 0.005195060279220343\n",
      "Key: 9, freq: (180, 200), freq sum: 0.032935481518507004\n",
      "Key: 10, freq: (200, 220), freq sum: 0.00926438719034195\n",
      "Key: 11, freq: (220, 240), freq sum: 0.024498241022229195\n",
      "Key: 12, freq: (240, 260), freq sum: 0.007468082010746002\n",
      "Key: 13, freq: (260, 280), freq sum: 0.012368181720376015\n",
      "Key: 14, freq: (280, 300), freq sum: 0.025637242943048477\n",
      "Key: 15, freq: (300, 320), freq sum: 0.02468782290816307\n",
      "Key: 16, freq: (320, 340), freq sum: 0.03239729255437851\n",
      "Key: 17, freq: (340, 360), freq sum: 0.0021987585350871086\n",
      "Key: 18, freq: (360, 380), freq sum: 0.04273342713713646\n",
      "Key: 19, freq: (380, 400), freq sum: 0.14143353700637817\n",
      "Key: 20, freq: (400, 420), freq sum: 0.04001133143901825\n",
      "Key: 21, freq: (420, 440), freq sum: 0.036046102643013\n",
      "Key: 22, freq: (440, 460), freq sum: 0.06607719510793686\n",
      "Key: 23, freq: (460, 480), freq sum: 0.004440189804881811\n",
      "Key: 25, freq: (500, 520), freq sum: 0.012700564227998257\n",
      "Key: 26, freq: (520, 540), freq sum: 0.04240274801850319\n",
      "Key: 27, freq: (540, 560), freq sum: 0.003398753935471177\n",
      "Key: 28, freq: (560, 580), freq sum: 0.05464306101202965\n",
      "Key: 29, freq: (580, 600), freq sum: 0.03603208065032959\n"
     ]
    }
   ],
   "source": [
    "for idy in low_diff_keys:\n",
    "    print(f\"Key: {idy}, freq: {idy*20,(idy+1)*20}, freq sum: {acts[0][idy*20:(idy+1)*20].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2261, 15114, 31698, 23478, 23322,  5929, 31855,  5719,  6873, 22354,\n",
       "         7851, 19673, 26619, 22183, 14871, 16769, 31778, 15127, 27452, 29834])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_freq_ind = torch.topk(acts[0], 20).indices\n",
    "high_freq_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 16.531463623046875\n",
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 16.531461715698242\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.743424844936504e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.743424844936504e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.1938104544788617e-13\n",
      "Key: blocks.2.ln2.hook_normalized, diff: 2.1938104544788617e-13\n",
      "Key: blocks.0.hook_resid_post.hook_sae_output, diff: 1.2656073563287185e-13\n",
      "Key: blocks.1.hook_resid_pre, diff: 1.2656073563287185e-13\n",
      "Key: blocks.3.ln1.hook_normalized, diff: 4.480038573190931e-14\n",
      "Key: blocks.3.ln2.hook_normalized, diff: 4.480038573190931e-14\n",
      "Key: blocks.1.hook_resid_post, diff: 4.352352760963671e-14\n",
      "Key: blocks.2.hook_resid_pre, diff: 4.352352760963671e-14\n",
      "Key: blocks.2.hook_resid_post, diff: 1.480289686401487e-14\n",
      "Key: blocks.3.hook_resid_pre, diff: 1.480289686401487e-14\n",
      "Key: blocks.4.ln1.hook_normalized, diff: 1.1919824563424043e-14\n",
      "Key: blocks.4.ln2.hook_normalized, diff: 1.1919824563424043e-14\n",
      "Key: blocks.3.hook_resid_post, diff: 4.605613748720223e-15\n",
      "Key: blocks.4.hook_resid_pre, diff: 4.605613748720223e-15\n",
      "Key: blocks.5.ln1.hook_normalized, diff: 3.3195350375420487e-15\n",
      "Key: blocks.5.ln2.hook_normalized, diff: 3.3195350375420487e-15\n",
      "Key: blocks.4.hook_resid_post, diff: 1.947366650462026e-15\n",
      "Key: blocks.5.hook_resid_pre, diff: 1.947366650462026e-15\n",
      "Key: blocks.1.ln1.hook_scale, diff: 4.427628091942216e-16\n",
      "Key: blocks.1.ln2.hook_scale, diff: 4.427628091942216e-16\n",
      "Key: hook_embed, diff: 0.0\n",
      "Key: blocks.0.hook_resid_pre, diff: 0.0\n",
      "Key: blocks.0.ln1.hook_scale, diff: 0.0\n",
      "Key: blocks.0.ln1.hook_normalized, diff: 0.0\n",
      "Key: blocks.0.attn.hook_q, diff: 0.0\n",
      "Key: blocks.0.attn.hook_k, diff: 0.0\n",
      "Key: blocks.0.attn.hook_v, diff: 0.0\n",
      "Key: blocks.0.attn.hook_rot_q, diff: 0.0\n",
      "Key: blocks.0.attn.hook_rot_k, diff: 0.0\n",
      "Key: blocks.0.attn.hook_attn_scores, diff: 0.0\n",
      "Key: blocks.0.attn.hook_pattern, diff: 0.0\n",
      "Key: blocks.0.attn.hook_z, diff: 0.0\n",
      "Key: blocks.0.hook_attn_out, diff: 0.0\n",
      "Key: blocks.0.ln2.hook_scale, diff: 0.0\n",
      "Key: blocks.0.ln2.hook_normalized, diff: 0.0\n",
      "Key: blocks.0.mlp.hook_pre, diff: 0.0\n",
      "Key: blocks.0.mlp.hook_post, diff: 0.0\n",
      "Key: blocks.0.hook_mlp_out, diff: 0.0\n",
      "Key: blocks.0.hook_resid_post.hook_sae_input, diff: 0.0\n",
      "Key: blocks.0.hook_resid_post.hook_sae_acts_pre, diff: 0.0\n",
      "Key: blocks.0.hook_resid_post.hook_sae_acts_post, diff: 0.0\n",
      "Key: blocks.1.attn.hook_q, diff: 0.0\n",
      "Key: blocks.1.attn.hook_k, diff: 0.0\n",
      "Key: blocks.1.attn.hook_v, diff: 0.0\n",
      "Key: blocks.1.attn.hook_rot_q, diff: 0.0\n",
      "Key: blocks.1.attn.hook_rot_k, diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "for idy in range(1):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    high_freq_ind = torch.topk(acts[0], 20).indices\n",
    "    list(map(lambda idx: sae2.W_dec[idx, :].zero_(), high_freq_ind))\n",
    "    cache = {}\n",
    "    for idx in tqdm(range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:50]\n",
    "    for key, _ in top_10_keys:\n",
    "        print(f\"Key: {key}, diff: {cache[key]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 16.531463623046875\n",
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 16.531461715698242\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.743424844936504e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.743424844936504e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.1938104544788617e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 518144.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 518144.0\n",
      "Key: blocks.4.attn.hook_q, diff: 31488.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 31488.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 13.959872245788574\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 13.959872245788574\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.1705226631714138e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.1705226631714138e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.2373341243900335e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 23.384490966796875\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 23.384490966796875\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.567503067790744e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.567503067790744e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.7798745333488797e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 47872.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 47872.0\n",
      "Key: blocks.4.attn.hook_q, diff: 16128.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 16128.0\n",
      "Key: blocks.3.attn.hook_q, diff: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:03<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 3.2196216583251953\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 3.2196216583251953\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.5134172087354356e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.5134172087354356e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.6868410422817004e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 328.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 328.0\n",
      "Key: blocks.4.attn.hook_q, diff: 49.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 49.0\n",
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 4.957878589630127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 518144.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 518144.0\n",
      "Key: blocks.4.attn.hook_q, diff: 31488.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 31488.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 2.0361340045928955\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 2.0361340045928955\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.951199618543953e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.951199618543953e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.1108814741570341e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 9.984151840209961\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 9.984151840209961\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.2955205484777021e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.2955205484777021e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.0608413250650798e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idy in range(10):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    high_freq_ind = torch.topk(acts[0], 200).indices[idy*20:(idy+1)*20]\n",
    "    list(map(lambda idx: sae2.W_dec[idx, :].zero_(), high_freq_ind))\n",
    "    cache = {}\n",
    "    for idx in tqdm(range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    for key, _ in top_10_keys:\n",
    "        print(f\"Key: {key}, diff: {cache[key]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_762/2141996977.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  acts = torch.load(\"../res/acts/pythia_freqs_code.pt\"), torch.load(\"../res/acts/pythia_freqs_math.pt\"), torch.load(\"../res/acts/pythia_freqs_wiki.pt\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "acts = torch.load(\"../res/acts/pythia_freqs_code.pt\"), torch.load(\"../res/acts/pythia_freqs_math.pt\"), torch.load(\"../res/acts/pythia_freqs_wiki.pt\")\n",
    "code_acts = acts[0]\n",
    "top_num = 600\n",
    "math_acts = acts[1]\n",
    "wiki_acts = acts[2]\n",
    "top_index_code = torch.topk(code_acts[0], top_num).indices\n",
    "top_index_math = torch.topk(math_acts[0], top_num).indices\n",
    "top_index_wiki = torch.topk(wiki_acts[0], top_num).indices\n",
    "top_index_mc = np.intersect1d(\n",
    "    top_index_code.cpu().numpy(), top_index_math.cpu().numpy()\n",
    ")\n",
    "top_index_mw = np.intersect1d(\n",
    "    top_index_math.cpu().numpy(), top_index_wiki.cpu().numpy()\n",
    ")\n",
    "top_index_cw = np.intersect1d(\n",
    "    top_index_code.cpu().numpy(), top_index_wiki.cpu().numpy()\n",
    ")\n",
    "top_index = np.intersect1d(top_index_mc, top_index_mw)\n",
    "top_index_mc = np.setdiff1d(top_index_mc, top_index)\n",
    "top_index_mw = np.setdiff1d(top_index_mw, top_index)\n",
    "top_index_cw = np.setdiff1d(top_index_cw, top_index)\n",
    "top_index_wiki = np.setdiff1d(\n",
    "    top_index_wiki.cpu().numpy(), np.union1d(top_index_cw, top_index_mw)\n",
    ")\n",
    "top_index_math = np.setdiff1d(\n",
    "    top_index_math.cpu().numpy(), np.union1d(top_index_mc, top_index_mw)\n",
    ")\n",
    "top_index_code = np.setdiff1d(\n",
    "    top_index_code.cpu().numpy(), np.union1d(top_index_mc, top_index_cw)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 956.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 956.0\n",
      "Key: blocks.4.attn.hook_q, diff: 37.25\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 37.25\n",
      "Key: blocks.5.attn.hook_z, diff: 17.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.4.attn.hook_q, diff: 1114112.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 1114112.0\n",
      "Key: blocks.5.attn.hook_q, diff: 557056.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 557056.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1344.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 10.239799499511719\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 10.239799499511719\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.8347571725807477e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.8347571725807477e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.3173855994801087e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 6.180593490600586\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 6.180593490600586\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.451221304585304e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.451221304585304e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.9223759682631542e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.4.attn.hook_q, diff: 1114112.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 1114112.0\n",
      "Key: blocks.5.attn.hook_q, diff: 790528.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 790528.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1544.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 3.2941243648529053\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 3.2941243648529053\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 9.386361046054281e-13\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 9.386361046054281e-13\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.5152428736644324e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 14.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 518144.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 518144.0\n",
      "Key: blocks.4.attn.hook_q, diff: 31488.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 31488.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1088.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:03<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 13.944974899291992\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 13.944974899291992\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 8.709892616171055e-13\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 8.709892616171055e-13\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.3085825554658842e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.4.attn.hook_q, diff: 1114112.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 1114112.0\n",
      "Key: blocks.5.attn.hook_q, diff: 557056.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 557056.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1344.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 518144.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 518144.0\n",
      "Key: blocks.4.attn.hook_q, diff: 31488.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 31488.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idy in range(10):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # high_freq_ind = torch.topk(acts[0], 200).indices[idy*20:(idy+1)*20]\n",
    "    list(map(lambda idx: sae2.W_dec[idx, :].zero_(), top_index_wiki[idy*20:(idy+1)*20]))\n",
    "    cache = {}\n",
    "    for idx in tqdm(range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    for key, _ in top_10_keys:\n",
    "        print(f\"Key: {key}, diff: {cache[key]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:03<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 13.48265552520752\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 13.48265552520752\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.1958689207235427e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.1958689207235427e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.0715604253686293e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 7.814596176147461\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 7.814596176147461\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.325803829042461e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.325803829042461e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.9443379740448352e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.4.attn.hook_q, diff: 1114112.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 1114112.0\n",
      "Key: blocks.5.attn.hook_q, diff: 557056.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 557056.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1344.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 5.345946788787842\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 5.345946788787842\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.1913498616442086e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.1913498616442086e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.1123085377182382e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 12.04269790649414\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 12.04269790649414\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.5058000419482243e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.5058000419482243e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.9243856725151276e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 15.020439147949219\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 15.020439147949219\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.0391405617926619e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.0391405617926619e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.0065345869221818e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 14.865419387817383\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 14.865419387817383\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.2863965535153676e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.2863965535153676e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.8092435373224386e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 13.859122276306152\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 13.859122276306152\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.238063684031899e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.238063684031899e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.7136722000200139e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 518144.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 518144.0\n",
      "Key: blocks.4.attn.hook_q, diff: 31488.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 31488.0\n",
      "Key: blocks.5.attn.hook_z, diff: 1072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 47872.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 47872.0\n",
      "Key: blocks.4.attn.hook_q, diff: 16128.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 16128.0\n",
      "Key: blocks.3.attn.hook_q, diff: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idy in range(10):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # high_freq_ind = torch.topk(acts[0], 200).indices[idy*20:(idy+1)*20]\n",
    "    list(map(lambda idx: sae2.W_dec[idx, :].zero_(), top_index[idy*20:(idy+1)*20]))\n",
    "    cache = {}\n",
    "    for idx in tqdm(range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    for key, _ in top_10_keys:\n",
    "        print(f\"Key: {key}, diff: {cache[key]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.09385795146226883\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.09385795146226883\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.1380096355279729e-13\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.1380096355279729e-13\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.0568670464765626e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.745274543762207\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.745274543762207\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.8457112194950748e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.8457112194950748e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 3.159188947769731e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 48896.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 48896.0\n",
      "Key: blocks.4.attn.hook_q, diff: 16128.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 16128.0\n",
      "Key: blocks.3.attn.hook_q, diff: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.5018693208694458\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.5018693208694458\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.3636395615121422e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.3636395615121422e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 4.0476282536176106e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.35401612520217896\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.35401612520217896\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.446167996893872e-13\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.446167996893872e-13\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 5.1379168660489055e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.12169844657182693\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.12169844657182693\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 3.4933431066483736e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 3.4933431066483736e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 3.954900168749893e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.0328533761203289\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.0328533761203289\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 4.102128047509847e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 4.102128047509847e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 7.602154582925236e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.0928812250494957\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.0928812250494957\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.924057344996442e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.924057344996442e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 7.519285114530611e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.029706424102187157\n",
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.02970641665160656\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 3.020013303019556e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 3.020013303019556e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 3.935749600845421e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.5.attn.hook_q, diff: 47872.0\n",
      "Key: blocks.5.attn.hook_rot_q, diff: 47872.0\n",
      "Key: blocks.4.attn.hook_q, diff: 16128.0\n",
      "Key: blocks.4.attn.hook_rot_q, diff: 16128.0\n",
      "Key: blocks.3.attn.hook_q, diff: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.5567302703857422\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.5567302703857422\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.2950299469946525e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.2950299469946525e-12\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 4.117576234401871e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.02535983920097351\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.02535983920097351\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 3.634435756364775e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 3.634435756364775e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 6.671486025975519e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.022813327610492706\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.022813327610492706\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.435543798161733e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.435543798161733e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 3.0139293618209597e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.012242822907865047\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.012242822907865047\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.0672251758269812e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.0672251758269812e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.1823406803038086e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:03<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.1277359127998352\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.1277359127998352\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.1234999097118588e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.1234999097118588e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.7613917825530104e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.13866767287254333\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.13866767287254333\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 8.207394182682681e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 8.207394182682681e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 2.0701270084526498e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.02830544486641884\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.02830544486641884\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.5786461357971196e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.5786461357971196e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.3438445582359044e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.20176245272159576\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.20176245272159576\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 2.007548553122681e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 2.007548553122681e-14\n",
      "Key: blocks.0.hook_resid_post.hook_sae_output, diff: 1.6352587263213396e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.042463518679142\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.042463518679142\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 4.653581732743002e-14\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 4.653581732743002e-14\n",
      "Key: blocks.2.ln1.hook_normalized, diff: 1.0091667424134455e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 16.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: blocks.0.hook_resid_post.hook_sae_recons, diff: 0.12521332502365112\n",
      "Key: blocks.0.hook_resid_post.hook_sae_error, diff: 0.12521332502365112\n",
      "Key: blocks.1.ln1.hook_normalized, diff: 1.5102062395772053e-12\n",
      "Key: blocks.1.ln2.hook_normalized, diff: 1.5102062395772053e-12\n",
      "Key: blocks.0.hook_resid_post.hook_sae_output, diff: 1.2372499299227475e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idy in range(20):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # high_freq_ind = torch.topk(acts[0], 200).indices[idy*20:(idy+1)*20]\n",
    "    list(map(lambda idx: sae2.W_dec[idx, :].zero_(), top_index_wiki[idy:(idy+1)]))\n",
    "    cache = {}\n",
    "    for idx in tqdm(range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    for key, _ in top_10_keys:\n",
    "        print(f\"Key: {key}, diff: {cache[key]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:56<00:00,  2.80s/it]\n"
     ]
    }
   ],
   "source": [
    "high_diff_keys = []\n",
    "low_diff_keys = []\n",
    "for idy in tqdm(range(20)):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # high_freq_ind = torch.topk(acts[0], 200).indices[idy*20:(idy+1)*20]\n",
    "    list(map(lambda idx: sae2.W_dec[idx, :].zero_(), top_index_wiki[idy:(idy+1)]))\n",
    "    cache = {}\n",
    "    for idx in (range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    flag = False\n",
    "    for key, _ in top_10_keys:\n",
    "        if key.startswith(\"blocks.5\"):\n",
    "            high_diff_keys.append(idy)\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        low_diff_keys.append(idy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High diff keys: [2, 9]\n",
      "Low diff keys: [0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "print(f\"High diff keys: {high_diff_keys}\")\n",
    "print(f\"Low diff keys: {low_diff_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0020), tensor(0.1736))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_acts[0][top_index_wiki[2]], code_acts[0][top_index_wiki[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaxtyping\n",
    "def get_cosine_similarity(\n",
    "    dict_elements_1: jaxtyping.Float[torch.Tensor, \"d_sae d_llm\"],\n",
    "    dict_elements_2: jaxtyping.Float[torch.Tensor, \"d_sae d_llm\"],\n",
    "    p: int = 2,\n",
    "    dim: int = 1,\n",
    "    normalized: bool = True,\n",
    ") -> jaxtyping.Float[torch.Tensor, \"d_llm d_llm\"]:\n",
    "    \"\"\"Get the cosine similarity between the dictionary elements.\n",
    "\n",
    "    Args:\n",
    "        dict_elements_1: The first dictionary elements.\n",
    "        dict_elements_2: The second dictionary elements.\n",
    "\n",
    "    Returns:\n",
    "        The cosine similarity between the dictionary elements.\n",
    "    \"\"\"\n",
    "    # Compute cosine similarity in pytorch\n",
    "    dict_elements_1 = dict_elements_1\n",
    "    dict_elements_2 = dict_elements_2\n",
    "\n",
    "    # Normalize the tensors\n",
    "    if normalized:\n",
    "        dict_elements_1 = torch.nn.functional.normalize(dict_elements_1, p=p, dim=dim)\n",
    "        dict_elements_2 = torch.nn.functional.normalize(dict_elements_2, p=p, dim=dim)\n",
    "\n",
    "    # Compute cosine similarity using matrix multiplication\n",
    "    cosine_sim: jaxtyping.Float[torch.Tensor, \"d_llm d_llm\"] = torch.mm(\n",
    "        dict_elements_1, dict_elements_2.T\n",
    "    )\n",
    "    # max_cosine_sim, _ = torch.max(cosine_sim, dim=1)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_2_dict(key1, key2):\n",
    "    return torch.mm(\n",
    "        torch.nn.functional.normalize(\n",
    "            sae1.W_dec[top_index_wiki[key1].item(), :].unsqueeze(0)\n",
    "        ),\n",
    "        torch.nn.functional.normalize(\n",
    "            sae1.W_dec[top_index_wiki[key2].item(), :].unsqueeze(0)\n",
    "        ).T,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key1: 0, Key2: 1, cosine similarity: tensor([[-0.0873]], device='cuda:0')\n",
      "Key1: 0, Key2: 3, cosine similarity: tensor([[0.0549]], device='cuda:0')\n",
      "Key1: 0, Key2: 4, cosine similarity: tensor([[0.0655]], device='cuda:0')\n",
      "Key1: 0, Key2: 5, cosine similarity: tensor([[0.1952]], device='cuda:0')\n",
      "Key1: 0, Key2: 6, cosine similarity: tensor([[0.0752]], device='cuda:0')\n",
      "Key1: 0, Key2: 7, cosine similarity: tensor([[0.1955]], device='cuda:0')\n",
      "Key1: 0, Key2: 8, cosine similarity: tensor([[-0.0638]], device='cuda:0')\n",
      "Key1: 0, Key2: 10, cosine similarity: tensor([[0.0563]], device='cuda:0')\n",
      "Key1: 0, Key2: 11, cosine similarity: tensor([[0.0815]], device='cuda:0')\n",
      "Key1: 0, Key2: 12, cosine similarity: tensor([[-0.0236]], device='cuda:0')\n",
      "Key1: 0, Key2: 13, cosine similarity: tensor([[0.0669]], device='cuda:0')\n",
      "Key1: 0, Key2: 14, cosine similarity: tensor([[-0.0653]], device='cuda:0')\n",
      "Key1: 0, Key2: 15, cosine similarity: tensor([[0.1375]], device='cuda:0')\n",
      "Key1: 0, Key2: 16, cosine similarity: tensor([[-0.1191]], device='cuda:0')\n",
      "Key1: 0, Key2: 17, cosine similarity: tensor([[-0.1254]], device='cuda:0')\n",
      "Key1: 0, Key2: 18, cosine similarity: tensor([[0.2127]], device='cuda:0')\n",
      "Key1: 0, Key2: 19, cosine similarity: tensor([[0.3117]], device='cuda:0')\n",
      "Key1: 1, Key2: 3, cosine similarity: tensor([[-0.3100]], device='cuda:0')\n",
      "Key1: 1, Key2: 4, cosine similarity: tensor([[-0.3267]], device='cuda:0')\n",
      "Key1: 1, Key2: 5, cosine similarity: tensor([[0.2643]], device='cuda:0')\n",
      "Key1: 1, Key2: 6, cosine similarity: tensor([[0.0371]], device='cuda:0')\n",
      "Key1: 1, Key2: 7, cosine similarity: tensor([[-0.0314]], device='cuda:0')\n",
      "Key1: 1, Key2: 8, cosine similarity: tensor([[0.0553]], device='cuda:0')\n",
      "Key1: 1, Key2: 10, cosine similarity: tensor([[0.0276]], device='cuda:0')\n",
      "Key1: 1, Key2: 11, cosine similarity: tensor([[0.0847]], device='cuda:0')\n",
      "Key1: 1, Key2: 12, cosine similarity: tensor([[0.0466]], device='cuda:0')\n",
      "Key1: 1, Key2: 13, cosine similarity: tensor([[0.0778]], device='cuda:0')\n",
      "Key1: 1, Key2: 14, cosine similarity: tensor([[0.0238]], device='cuda:0')\n",
      "Key1: 1, Key2: 15, cosine similarity: tensor([[0.4150]], device='cuda:0')\n",
      "Key1: 1, Key2: 16, cosine similarity: tensor([[-0.1040]], device='cuda:0')\n",
      "Key1: 1, Key2: 17, cosine similarity: tensor([[-0.0703]], device='cuda:0')\n",
      "Key1: 1, Key2: 18, cosine similarity: tensor([[0.0952]], device='cuda:0')\n",
      "Key1: 1, Key2: 19, cosine similarity: tensor([[0.0478]], device='cuda:0')\n",
      "Key1: 3, Key2: 4, cosine similarity: tensor([[0.2380]], device='cuda:0')\n",
      "Key1: 3, Key2: 5, cosine similarity: tensor([[-0.4151]], device='cuda:0')\n",
      "Key1: 3, Key2: 6, cosine similarity: tensor([[-0.0992]], device='cuda:0')\n",
      "Key1: 3, Key2: 7, cosine similarity: tensor([[-0.0382]], device='cuda:0')\n",
      "Key1: 3, Key2: 8, cosine similarity: tensor([[-0.0572]], device='cuda:0')\n",
      "Key1: 3, Key2: 10, cosine similarity: tensor([[0.1921]], device='cuda:0')\n",
      "Key1: 3, Key2: 11, cosine similarity: tensor([[-0.0735]], device='cuda:0')\n",
      "Key1: 3, Key2: 12, cosine similarity: tensor([[-0.0654]], device='cuda:0')\n",
      "Key1: 3, Key2: 13, cosine similarity: tensor([[-0.1452]], device='cuda:0')\n",
      "Key1: 3, Key2: 14, cosine similarity: tensor([[0.0258]], device='cuda:0')\n",
      "Key1: 3, Key2: 15, cosine similarity: tensor([[-0.4475]], device='cuda:0')\n",
      "Key1: 3, Key2: 16, cosine similarity: tensor([[0.1617]], device='cuda:0')\n",
      "Key1: 3, Key2: 17, cosine similarity: tensor([[0.0408]], device='cuda:0')\n",
      "Key1: 3, Key2: 18, cosine similarity: tensor([[0.0886]], device='cuda:0')\n",
      "Key1: 3, Key2: 19, cosine similarity: tensor([[-0.2032]], device='cuda:0')\n",
      "Key1: 4, Key2: 5, cosine similarity: tensor([[-0.2529]], device='cuda:0')\n",
      "Key1: 4, Key2: 6, cosine similarity: tensor([[-0.0525]], device='cuda:0')\n",
      "Key1: 4, Key2: 7, cosine similarity: tensor([[0.0480]], device='cuda:0')\n",
      "Key1: 4, Key2: 8, cosine similarity: tensor([[0.0299]], device='cuda:0')\n",
      "Key1: 4, Key2: 10, cosine similarity: tensor([[-0.1702]], device='cuda:0')\n",
      "Key1: 4, Key2: 11, cosine similarity: tensor([[-0.0210]], device='cuda:0')\n",
      "Key1: 4, Key2: 12, cosine similarity: tensor([[-0.0973]], device='cuda:0')\n",
      "Key1: 4, Key2: 13, cosine similarity: tensor([[-0.0703]], device='cuda:0')\n",
      "Key1: 4, Key2: 14, cosine similarity: tensor([[0.0146]], device='cuda:0')\n",
      "Key1: 4, Key2: 15, cosine similarity: tensor([[-0.1595]], device='cuda:0')\n",
      "Key1: 4, Key2: 16, cosine similarity: tensor([[0.2061]], device='cuda:0')\n",
      "Key1: 4, Key2: 17, cosine similarity: tensor([[0.1157]], device='cuda:0')\n",
      "Key1: 4, Key2: 18, cosine similarity: tensor([[-0.0428]], device='cuda:0')\n",
      "Key1: 4, Key2: 19, cosine similarity: tensor([[0.1096]], device='cuda:0')\n",
      "Key1: 5, Key2: 6, cosine similarity: tensor([[0.1224]], device='cuda:0')\n",
      "Key1: 5, Key2: 7, cosine similarity: tensor([[0.1613]], device='cuda:0')\n",
      "Key1: 5, Key2: 8, cosine similarity: tensor([[0.0446]], device='cuda:0')\n",
      "Key1: 5, Key2: 10, cosine similarity: tensor([[0.3059]], device='cuda:0')\n",
      "Key1: 5, Key2: 11, cosine similarity: tensor([[0.2847]], device='cuda:0')\n",
      "Key1: 5, Key2: 12, cosine similarity: tensor([[0.3327]], device='cuda:0')\n",
      "Key1: 5, Key2: 13, cosine similarity: tensor([[0.0808]], device='cuda:0')\n",
      "Key1: 5, Key2: 14, cosine similarity: tensor([[0.0002]], device='cuda:0')\n",
      "Key1: 5, Key2: 15, cosine similarity: tensor([[0.3013]], device='cuda:0')\n",
      "Key1: 5, Key2: 16, cosine similarity: tensor([[-0.3344]], device='cuda:0')\n",
      "Key1: 5, Key2: 17, cosine similarity: tensor([[-0.3119]], device='cuda:0')\n",
      "Key1: 5, Key2: 18, cosine similarity: tensor([[0.0970]], device='cuda:0')\n",
      "Key1: 5, Key2: 19, cosine similarity: tensor([[0.2172]], device='cuda:0')\n",
      "Key1: 6, Key2: 7, cosine similarity: tensor([[-0.1365]], device='cuda:0')\n",
      "Key1: 6, Key2: 8, cosine similarity: tensor([[-0.0472]], device='cuda:0')\n",
      "Key1: 6, Key2: 10, cosine similarity: tensor([[-0.0606]], device='cuda:0')\n",
      "Key1: 6, Key2: 11, cosine similarity: tensor([[0.1442]], device='cuda:0')\n",
      "Key1: 6, Key2: 12, cosine similarity: tensor([[0.0653]], device='cuda:0')\n",
      "Key1: 6, Key2: 13, cosine similarity: tensor([[0.0528]], device='cuda:0')\n",
      "Key1: 6, Key2: 14, cosine similarity: tensor([[0.0884]], device='cuda:0')\n",
      "Key1: 6, Key2: 15, cosine similarity: tensor([[0.1429]], device='cuda:0')\n",
      "Key1: 6, Key2: 16, cosine similarity: tensor([[0.2420]], device='cuda:0')\n",
      "Key1: 6, Key2: 17, cosine similarity: tensor([[0.0050]], device='cuda:0')\n",
      "Key1: 6, Key2: 18, cosine similarity: tensor([[0.0896]], device='cuda:0')\n",
      "Key1: 6, Key2: 19, cosine similarity: tensor([[0.0772]], device='cuda:0')\n",
      "Key1: 7, Key2: 8, cosine similarity: tensor([[0.0145]], device='cuda:0')\n",
      "Key1: 7, Key2: 10, cosine similarity: tensor([[0.0198]], device='cuda:0')\n",
      "Key1: 7, Key2: 11, cosine similarity: tensor([[0.2172]], device='cuda:0')\n",
      "Key1: 7, Key2: 12, cosine similarity: tensor([[0.0038]], device='cuda:0')\n",
      "Key1: 7, Key2: 13, cosine similarity: tensor([[0.0448]], device='cuda:0')\n",
      "Key1: 7, Key2: 14, cosine similarity: tensor([[-0.0343]], device='cuda:0')\n",
      "Key1: 7, Key2: 15, cosine similarity: tensor([[0.1119]], device='cuda:0')\n",
      "Key1: 7, Key2: 16, cosine similarity: tensor([[-0.1439]], device='cuda:0')\n",
      "Key1: 7, Key2: 17, cosine similarity: tensor([[-0.1392]], device='cuda:0')\n",
      "Key1: 7, Key2: 18, cosine similarity: tensor([[0.0560]], device='cuda:0')\n",
      "Key1: 7, Key2: 19, cosine similarity: tensor([[0.2330]], device='cuda:0')\n",
      "Key1: 8, Key2: 10, cosine similarity: tensor([[0.0451]], device='cuda:0')\n",
      "Key1: 8, Key2: 11, cosine similarity: tensor([[0.0422]], device='cuda:0')\n",
      "Key1: 8, Key2: 12, cosine similarity: tensor([[0.1262]], device='cuda:0')\n",
      "Key1: 8, Key2: 13, cosine similarity: tensor([[0.1307]], device='cuda:0')\n",
      "Key1: 8, Key2: 14, cosine similarity: tensor([[-0.1585]], device='cuda:0')\n",
      "Key1: 8, Key2: 15, cosine similarity: tensor([[0.0738]], device='cuda:0')\n",
      "Key1: 8, Key2: 16, cosine similarity: tensor([[0.1357]], device='cuda:0')\n",
      "Key1: 8, Key2: 17, cosine similarity: tensor([[-0.0855]], device='cuda:0')\n",
      "Key1: 8, Key2: 18, cosine similarity: tensor([[-0.0330]], device='cuda:0')\n",
      "Key1: 8, Key2: 19, cosine similarity: tensor([[-0.1338]], device='cuda:0')\n",
      "Key1: 10, Key2: 11, cosine similarity: tensor([[0.2548]], device='cuda:0')\n",
      "Key1: 10, Key2: 12, cosine similarity: tensor([[0.2101]], device='cuda:0')\n",
      "Key1: 10, Key2: 13, cosine similarity: tensor([[-0.0303]], device='cuda:0')\n",
      "Key1: 10, Key2: 14, cosine similarity: tensor([[-0.0225]], device='cuda:0')\n",
      "Key1: 10, Key2: 15, cosine similarity: tensor([[0.0254]], device='cuda:0')\n",
      "Key1: 10, Key2: 16, cosine similarity: tensor([[-0.1670]], device='cuda:0')\n",
      "Key1: 10, Key2: 17, cosine similarity: tensor([[-0.1930]], device='cuda:0')\n",
      "Key1: 10, Key2: 18, cosine similarity: tensor([[-0.1636]], device='cuda:0')\n",
      "Key1: 10, Key2: 19, cosine similarity: tensor([[-0.3562]], device='cuda:0')\n",
      "Key1: 11, Key2: 12, cosine similarity: tensor([[0.0337]], device='cuda:0')\n",
      "Key1: 11, Key2: 13, cosine similarity: tensor([[0.0058]], device='cuda:0')\n",
      "Key1: 11, Key2: 14, cosine similarity: tensor([[0.0585]], device='cuda:0')\n",
      "Key1: 11, Key2: 15, cosine similarity: tensor([[0.0788]], device='cuda:0')\n",
      "Key1: 11, Key2: 16, cosine similarity: tensor([[-0.0042]], device='cuda:0')\n",
      "Key1: 11, Key2: 17, cosine similarity: tensor([[-0.2451]], device='cuda:0')\n",
      "Key1: 11, Key2: 18, cosine similarity: tensor([[0.1681]], device='cuda:0')\n",
      "Key1: 11, Key2: 19, cosine similarity: tensor([[0.0485]], device='cuda:0')\n",
      "Key1: 12, Key2: 13, cosine similarity: tensor([[0.0296]], device='cuda:0')\n",
      "Key1: 12, Key2: 14, cosine similarity: tensor([[-0.0391]], device='cuda:0')\n",
      "Key1: 12, Key2: 15, cosine similarity: tensor([[0.0377]], device='cuda:0')\n",
      "Key1: 12, Key2: 16, cosine similarity: tensor([[-0.0750]], device='cuda:0')\n",
      "Key1: 12, Key2: 17, cosine similarity: tensor([[-0.1024]], device='cuda:0')\n",
      "Key1: 12, Key2: 18, cosine similarity: tensor([[0.0483]], device='cuda:0')\n",
      "Key1: 12, Key2: 19, cosine similarity: tensor([[0.0413]], device='cuda:0')\n",
      "Key1: 13, Key2: 14, cosine similarity: tensor([[0.0088]], device='cuda:0')\n",
      "Key1: 13, Key2: 15, cosine similarity: tensor([[0.1467]], device='cuda:0')\n",
      "Key1: 13, Key2: 16, cosine similarity: tensor([[-0.0547]], device='cuda:0')\n",
      "Key1: 13, Key2: 17, cosine similarity: tensor([[-0.0525]], device='cuda:0')\n",
      "Key1: 13, Key2: 18, cosine similarity: tensor([[0.0898]], device='cuda:0')\n",
      "Key1: 13, Key2: 19, cosine similarity: tensor([[0.0811]], device='cuda:0')\n",
      "Key1: 14, Key2: 15, cosine similarity: tensor([[0.0429]], device='cuda:0')\n",
      "Key1: 14, Key2: 16, cosine similarity: tensor([[0.0471]], device='cuda:0')\n",
      "Key1: 14, Key2: 17, cosine similarity: tensor([[-0.0484]], device='cuda:0')\n",
      "Key1: 14, Key2: 18, cosine similarity: tensor([[-0.0142]], device='cuda:0')\n",
      "Key1: 14, Key2: 19, cosine similarity: tensor([[-0.0305]], device='cuda:0')\n",
      "Key1: 15, Key2: 16, cosine similarity: tensor([[-0.0143]], device='cuda:0')\n",
      "Key1: 15, Key2: 17, cosine similarity: tensor([[-0.0414]], device='cuda:0')\n",
      "Key1: 15, Key2: 18, cosine similarity: tensor([[0.0081]], device='cuda:0')\n",
      "Key1: 15, Key2: 19, cosine similarity: tensor([[0.2196]], device='cuda:0')\n",
      "Key1: 16, Key2: 17, cosine similarity: tensor([[0.0404]], device='cuda:0')\n",
      "Key1: 16, Key2: 18, cosine similarity: tensor([[0.0238]], device='cuda:0')\n",
      "Key1: 16, Key2: 19, cosine similarity: tensor([[-0.1273]], device='cuda:0')\n",
      "Key1: 17, Key2: 18, cosine similarity: tensor([[-0.1529]], device='cuda:0')\n",
      "Key1: 17, Key2: 19, cosine similarity: tensor([[0.0167]], device='cuda:0')\n",
      "Key1: 18, Key2: 19, cosine similarity: tensor([[0.1508]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(low_diff_keys)):\n",
    "    for idy in range(idx+1, len(low_diff_keys)):\n",
    "        print(f\"Key1: {low_diff_keys[idx]}, Key2: {low_diff_keys[idy]}, cosine similarity: {cs_2_dict(low_diff_keys[idx], low_diff_keys[idy])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key1: 2, Key2: 2, cosine similarity: tensor([[1.]], device='cuda:0')\n",
      "Key1: 2, Key2: 9, cosine similarity: tensor([[-0.2480]], device='cuda:0')\n",
      "Key1: 9, Key2: 2, cosine similarity: tensor([[-0.2480]], device='cuda:0')\n",
      "Key1: 9, Key2: 9, cosine similarity: tensor([[1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for key1 in high_diff_keys:\n",
    "    for key2 in high_diff_keys:\n",
    "        print(f\"Key1: {key1}, Key2: {key2}, cosine similarity: {cs_2_dict(key1, key2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:48,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:05<00:48,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:08<00:46,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high diff, the loss diff is 109568.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:10<00:43,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:13<00:39,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:15<00:36,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:18<00:32,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:32<01:13,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:34<00:55,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:37<00:42,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high diff, the loss diff is 90112.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:39<00:33,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:42<00:26,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:44<00:21,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:47<00:17,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:49<00:13,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:52<00:10,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:54<00:07,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:56<00:05,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:59<00:02,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:03<00:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low diff, the loss diff is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "high_diff_keys = []\n",
    "low_diff_keys = []\n",
    "for idy in tqdm(range(20)):\n",
    "    model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "    layers = 6\n",
    "    torch.set_grad_enabled(False)\n",
    "    release = \"pythia-70m-deduped-res-sm\"\n",
    "    sae_id = \"blocks.0.hook_resid_post\"\n",
    "    sae1 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    ds_ratio = 1e-3\n",
    "    dataset_length = int(len(dataset) * ds_ratio)\n",
    "    use_error_term = True\n",
    "    freqs = torch.zeros(sae1.cfg.d_sae)\n",
    "    doc_len = 0\n",
    "    sae2 = sae_lens.SAE.from_pretrained(release, sae_id, device=\"cuda\")[0]\n",
    "    # high_freq_ind = torch.topk(acts[0], 200).indices[idy*20:(idy+1)*20]\n",
    "    list(map(lambda idx: sae2.W_dec[idx, :].zero_(), top_index_wiki[idy:(idy+1)]))\n",
    "    cache = {}\n",
    "    loss = 0\n",
    "    for idx in (range(dataset_length)):\n",
    "        example = dataset[idx]\n",
    "        tokens = model.to_tokens([example[text]], prepend_bos=True)\n",
    "        loss1, cache1 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae1, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        local_doc_len = cache1[f\"blocks.0.hook_resid_post.hook_sae_acts_post\"].shape[1]\n",
    "        new_doc_len = doc_len + local_doc_len\n",
    "\n",
    "        freq = (\n",
    "            cache1[\"blocks.0.hook_resid_post.hook_sae_acts_post\"]\n",
    "            > 1)[0].sum(0) / local_doc_len\n",
    "        loss2, cache2 = model.run_with_cache_with_saes(\n",
    "            tokens, saes=sae2, use_error_term=use_error_term\n",
    "        )\n",
    "        model.reset_saes()\n",
    "        for keys in cache1.keys():\n",
    "            if torch.isnan(cache1[keys]).any() or torch.isnan(cache2[keys]).any():\n",
    "                continue\n",
    "            res = ((cache1[keys] - cache2[keys]) ** 2).sum()\n",
    "            if torch.isnan(res):\n",
    "                if idx == 0:\n",
    "                    cache[keys] = 0\n",
    "                continue\n",
    "            if idx == 0:\n",
    "                cache[keys] = res\n",
    "            else:\n",
    "                cache[keys] = (\n",
    "                    cache[keys] * doc_len / new_doc_len\n",
    "                    + res * local_doc_len / new_doc_len\n",
    "                )\n",
    "        doc_len = new_doc_len\n",
    "        loss += ((loss1 - loss2) ** 2).sum()\n",
    "    def value_getter(item):\n",
    "        return item[1]\n",
    "\n",
    "    top_10_keys = sorted(cache.items(), key=value_getter, reverse=True)[:5]\n",
    "    flag = False\n",
    "    for key, _ in top_10_keys:\n",
    "        if key.startswith(\"blocks.5\"):\n",
    "            high_diff_keys.append(idy)\n",
    "            print(f\"high diff, the loss diff is {loss}\")\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        low_diff_keys.append(idy)\n",
    "        print(f\"low diff, the loss diff is {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO1: check the structure of the model and see the location of the hook\n",
    "# TODO2: check the attribute methods and see its influence on the output and frequency patterns\n",
    "# TODO3: cos sim and high dim vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hook_embed: Likely used to capture or modify the embeddings of the input tokens before they are fed into the model.\n",
    "\n",
    "blocks.0.hook_resid_pre: Captures or modifies the residual connection input before any processing in the first block.\n",
    "\n",
    "blocks.0.ln1.hook_scale: Captures or modifies the scaling factor in the first layer normalization of the first block.\n",
    "\n",
    "blocks.0.ln1.hook_normalized: Captures or modifies the normalized output in the first layer normalization of the first block.\n",
    "\n",
    "blocks.0.attn.hook_q: Captures or modifies the query vectors in the attention mechanism of the first block.\n",
    "\n",
    "blocks.0.attn.hook_k: Captures or modifies the key vectors in the attention mechanism of the first block.\n",
    "\n",
    "blocks.0.attn.hook_v: Captures or modifies the value vectors in the attention mechanism of the first block.\n",
    "\n",
    "blocks.0.attn.hook_rot_q: Captures or modifies the rotated query vectors, possibly for rotary positional embeddings.\n",
    "\n",
    "blocks.0.attn.hook_rot_k: Captures or modifies the rotated key vectors, possibly for rotary positional embeddings.\n",
    "\n",
    "blocks.0.attn.hook_attn_scores: Captures or modifies the attention scores before the softmax operation.\n",
    "\n",
    "blocks.0.attn.hook_pattern: Captures or modifies the attention pattern after the softmax operation.\n",
    "\n",
    "blocks.0.attn.hook_z: Captures or modifies the output of the attention mechanism.\n",
    "\n",
    "blocks.0.hook_attn_out: Captures or modifies the output of the attention mechanism before it is added to the residual connection.\n",
    "\n",
    "blocks.0.ln2.hook_scale: Captures or modifies the scaling factor in the second layer normalization of the first block.\n",
    "\n",
    "blocks.0.ln2.hook_normalized: Captures or modifies the normalized output in the second layer normalization of the first block.\n",
    "\n",
    "blocks.0.mlp.hook_pre: Captures or modifies the input to the multi-layer perceptron (MLP) in the first block.\n",
    "\n",
    "blocks.0.mlp.hook_post: Captures or modifies the output of the MLP in the first block.\n",
    "\n",
    "blocks.0.hook_mlp_out: Captures or modifies the output of the MLP before it is added to the residual connection.\n",
    "\n",
    "blocks.0.hook_resid_post.hook_sae_input: Likely captures or modifies the input to a sub-module or sub-layer within the residual connection post-processing.\n",
    "\n",
    "blocks.0.hook_resid_post.hook_sae_acts_pre: Likely captures or modifies the activations before some specific operation within the residual connection post-processing.\n",
    "\n",
    "blocks.0.hook_resid_post.hook_sae_acts_post: Likely captures or modifies the activations after some specific operation within the residual connection post-processing.\n",
    "\n",
    "blocks.0.hook_resid_post.hook_sae_recons: Likely captures or modifies the reconstructed output within the residual connection post-processing.\n",
    "\n",
    "blocks.0.hook_resid_post.hook_sae_output: Likely captures or modifies the final output within the residual connection post-processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saegeometry-1tp4usyN-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
