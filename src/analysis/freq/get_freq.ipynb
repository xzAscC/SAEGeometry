{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1734/740336833.py:16: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_1734/740336833.py:17: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "DEVELOPMENT_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install git+https://github.com/jbloomAus/SAELens\n",
    "\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f7608eb0200>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/code/sae/SAE_Geometry/.venv/lib/python3.12/site-packages/einops/einops.py:827: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/mnt/d/code/sae/SAE_Geometry/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import HookedSAETransformer\n",
    "\n",
    "model: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gpt2-small\").to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blocks.0.hook_resid_pre', 'blocks.1.hook_resid_pre', 'blocks.2.hook_resid_pre', 'blocks.3.hook_resid_pre', 'blocks.4.hook_resid_pre', 'blocks.5.hook_resid_pre', 'blocks.6.hook_resid_pre', 'blocks.7.hook_resid_pre', 'blocks.8.hook_resid_pre', 'blocks.9.hook_resid_pre', 'blocks.10.hook_resid_pre', 'blocks.11.hook_resid_pre'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from sae_lens import SAE\n",
    "\n",
    "hook_name_to_sae = {}\n",
    "for layer in tqdm.tqdm(range(12)):\n",
    "    sae, cfg_dict, _ = SAE.from_pretrained(\n",
    "        \"gpt2-small-res-jb\",\n",
    "        f\"blocks.{layer}.hook_resid_pre\",\n",
    "        device=device,\n",
    "    )\n",
    "    hook_name_to_sae[sae.cfg.hook_name] = sae\n",
    "\n",
    "print(hook_name_to_sae.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAEConfig(architecture='standard', d_in=768, d_sae=24576, activation_fn_str='relu', apply_b_dec_to_input=True, finetuning_scaling_factor=False, context_size=128, model_name='gpt2-small', hook_name='blocks.7.hook_resid_pre', hook_layer=7, hook_head_index=None, prepend_bos=True, dataset_path='Skylion007/openwebtext', dataset_trust_remote_code=True, normalize_activations='none', dtype='torch.float32', device='cuda', sae_lens_training_version=None, activation_fn_kwargs={}, neuronpedia_id='gpt2-small/7-res-jb', model_from_pretrained_kwargs={'center_writing_weights': True}, seqpos_slice=(None,))\n"
     ]
    }
   ],
   "source": [
    "import transformer_lens.utils as utils\n",
    "\n",
    "layer = 7\n",
    "layer_name = f\"blocks.{layer}.hook_resid_pre\"\n",
    "sae = hook_name_to_sae[layer_name]\n",
    "print(sae.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'gpt2-small', 'hook_point': 'blocks.11.hook_resid_pre', 'hook_point_layer': 11, 'hook_point_head_index': None, 'dataset_path': 'Skylion007/openwebtext', 'is_dataset_tokenized': False, 'context_size': 128, 'use_cached_activations': False, 'cached_activations_path': 'activations/Skylion007_openwebtext/gpt2-small/blocks.11.hook_resid_pre', 'd_in': 768, 'n_batches_in_buffer': 128, 'total_training_tokens': 300000000, 'store_batch_size': 32, 'device': 'cuda', 'seed': 42, 'dtype': 'torch.float32', 'b_dec_init_method': 'geometric_median', 'expansion_factor': 32, 'from_pretrained_path': None, 'l1_coefficient': 8e-05, 'lr': 0.0004, 'lr_scheduler_name': None, 'lr_warm_up_steps': 5000, 'train_batch_size': 4096, 'use_ghost_grads': False, 'feature_sampling_window': 1000, 'feature_sampling_method': None, 'resample_batches': 1028, 'feature_reinit_scale': 0.2, 'dead_feature_window': 5000, 'dead_feature_estimation_method': 'no_fire', 'dead_feature_threshold': 1e-08, 'log_to_wandb': True, 'wandb_project': 'mats_sae_training_gpt2_small_resid_pre_5', 'wandb_entity': None, 'wandb_log_frequency': 100, 'n_checkpoints': 10, 'checkpoint_path': 'checkpoints/gf296egd', 'd_sae': 24576, 'tokens_per_buffer': 67108864, 'run_name': '24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08', 'model_from_pretrained_kwargs': {'center_writing_weights': True}, 'neuronpedia_id': 'gpt2-small/11-res-jb', 'prepend_bos': True, 'dataset_trust_remote_code': True, 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': False, 'sae_lens_training_version': None, 'activation_fn_str': 'relu', 'architecture': 'standard', 'normalize_activations': 'none'}\n"
     ]
    }
   ],
   "source": [
    "print(cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When John and Mary went to the shops, Mary gave the bag to', 'When John and Mary went to the shops, John gave the bag to', 'When Tom and James went to the park, James gave the ball to', 'When Tom and James went to the park, Tom gave the ball to', 'When Dan and Sid went to the shops, Sid gave an apple to', 'When Dan and Sid went to the shops, Dan gave an apple to', 'After Martin and Amy went to the park, Amy gave a drink to', 'After Martin and Amy went to the park, Martin gave a drink to']\n",
      "[(' John', ' Mary'), (' Mary', ' John'), (' Tom', ' James'), (' James', ' Tom'), (' Dan', ' Sid'), (' Sid', ' Dan'), (' Martin', ' Amy'), (' Amy', ' Martin')]\n"
     ]
    }
   ],
   "source": [
    "prompt_format = [\n",
    "    \"When John and Mary went to the shops,{} gave the bag to\",\n",
    "    \"When Tom and James went to the park,{} gave the ball to\",\n",
    "    \"When Dan and Sid went to the shops,{} gave an apple to\",\n",
    "    \"After Martin and Amy went to the park,{} gave a drink to\",\n",
    "]\n",
    "names = [\n",
    "    (\n",
    "        \" John\",\n",
    "        \" Mary\",\n",
    "    ),\n",
    "    (\" Tom\", \" James\"),\n",
    "    (\" Dan\", \" Sid\"),\n",
    "    (\" Martin\", \" Amy\"),\n",
    "]\n",
    "# List of prompts\n",
    "prompts = []\n",
    "# List of answers, in the format (correct, incorrect)\n",
    "answers = []\n",
    "# List of the token (ie an integer) corresponding to each answer, in the format (correct_token, incorrect_token)\n",
    "answer_tokens = []\n",
    "for i in range(len(prompt_format)):\n",
    "    for j in range(2):\n",
    "        answers.append((names[i][j], names[i][1 - j]))\n",
    "        answer_tokens.append(\n",
    "            (\n",
    "                model.to_single_token(answers[-1][0]),\n",
    "                model.to_single_token(answers[-1][1]),\n",
    "            )\n",
    "        )\n",
    "        # Insert the *incorrect* answer to the prompt, making the correct answer the indirect object.\n",
    "        prompts.append(prompt_format[i].format(answers[-1][1]))\n",
    "answer_tokens = torch.tensor(answer_tokens).to(device)\n",
    "print(prompts)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache_with_saes(tokens, saes=[sae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre.hook_sae_input', 'blocks.7.hook_resid_pre.hook_sae_acts_pre', 'blocks.7.hook_resid_pre.hook_sae_acts_post', 'blocks.7.hook_resid_pre.hook_sae_recons', 'blocks.7.hook_resid_pre.hook_sae_output', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']\n"
     ]
    }
   ],
   "source": [
    "print(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 24576])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [bz, sz, saz] (batch_size, sequence_size, sae_activation_size)\n",
    "cache['blocks.7.hook_resid_pre.hook_sae_acts_post'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_acts = cache['blocks.7.hook_resid_pre.hook_sae_acts_post']\n",
    "live_feature = sae_acts > 0\n",
    "live_feature_union = live_feature.any(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 24576])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live_feature_union.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(live_feature_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10979.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1097, -0.3123, -0.1200,  0.1681,  0.1030],\n",
      "        [-0.3123,  3.0602, -0.4328,  0.5485,  0.3888],\n",
      "        [-0.1200, -0.4328,  1.2228, -0.5980, -0.7856],\n",
      "        [ 0.1681,  0.5485, -0.5980,  0.7467,  0.5058],\n",
      "        [ 0.1030,  0.3888, -0.7856,  0.5058,  0.5374]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: speed up\n",
    "\n",
    "def cosine_similarity_by_column(matrix):\n",
    "    # Normalize each column vector\n",
    "    matrix = matrix.float()\n",
    "    cos_sim = torch.zeros(matrix.shape[1], matrix.shape[1])\n",
    "    for i in tqdm.tqdm(range(matrix.shape[1])):\n",
    "        cos_sim[:, i] = torch.mm(matrix.T, matrix[:, i].unsqueeze(1)).reshape(-1)\n",
    "    \n",
    "    return cos_sim\n",
    "\n",
    "# Example usage\n",
    "matrix = torch.randn(3, 5)  # Example matrix with 5 rows and 3 columns\n",
    "cos_sim_matrix = cosine_similarity_by_column(matrix)\n",
    "print(cos_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24576/24576 [00:10<00:00, 2256.06it/s]\n"
     ]
    }
   ],
   "source": [
    "sim = cosine_similarity_by_column(live_feature_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24576, 24576])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([146527, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(sim).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/code/sae/SAE_Geometry/.venv/lib/python3.12/site-packages/datasets/load.py:1454: FutureWarning: The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████████████████████████████████████████████████████| 2.73k/2.73k [00:00<00:00, 31.8MB/s]\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████| 7.35k/7.35k [00:00<00:00, 15.4MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 633M/633M [00:09<00:00, 64.2MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 629M/629M [00:09<00:00, 63.4MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 629M/629M [00:13<00:00, 47.4MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 628M/628M [00:09<00:00, 64.1MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 627M/627M [00:09<00:00, 63.8MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 630M/630M [00:13<00:00, 48.0MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 626M/626M [00:09<00:00, 64.0MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 625M/625M [00:09<00:00, 62.7MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 625M/625M [00:13<00:00, 48.0MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 626M/626M [00:09<00:00, 63.2MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 625M/625M [00:09<00:00, 64.3MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 625M/625M [00:12<00:00, 49.0MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 624M/624M [00:10<00:00, 62.1MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 629M/629M [00:10<00:00, 61.9MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 627M/627M [00:12<00:00, 50.6MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 621M/621M [00:10<00:00, 61.5MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 619M/619M [00:10<00:00, 61.0MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 619M/619M [00:13<00:00, 46.3MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 618M/618M [00:10<00:00, 59.3MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 619M/619M [00:10<00:00, 60.3MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████| 377M/377M [00:06<00:00, 60.2MB/s]\n",
      "Generating train split: 100%|███████████████████████████████████████████████| 8013769/8013769 [11:13<00:00, 11894.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Port-au-Prince, Haiti (CNN) -- Earthquake victims, writhing in pain and grasping at life, watched doctors and nurses walk away from a field hospital Friday night after a Belgian medical team evacuated the area, saying it was concerned about security.\\n\\nThe decision left CNN Chief Medical Correspondent Sanjay Gupta as the only doctor at the hospital to get the patients through the night.\\n\\nCNN initially reported, based on conversations with some of the doctors, that the United Nations ordered the Belgian First Aid and Support Team to evacuate. However, Belgian Chief Coordinator Geert Gijs, a doctor who was at the hospital with 60 Belgian medical personnel, said it was his decision to pull the team out for the night. Gijs said he requested U.N. security personnel to staff the hospital overnight, but was told that peacekeepers would only be able to evacuate the team.\\n\\nHe said it was a \"tough decision\" but that he accepted the U.N. offer to evacuate after a Canadian medical team, also at the hospital with Canadian security officers, left the site Friday afternoon. The Belgian team returned Saturday morning.\\n\\nGijs said the United Nations has agreed to provide security for Saturday night. The team has requested the Belgian government to send its own troops for the field hospital, which Gijs expects to arrive late Sunday.\\n\\nResponding to the CNN report that Gupta was the only doctor left at the Port-au-Prince field hospital, U.N. spokesman Martin Nesirky said Saturday that the world body\\'s mission in Haiti did not order any medical team to leave. If the team left, it was at the request of their own organization, he said.\\n\\nEdmond Mulet, the U.N. assistant secretary general for peacekeeping operations, told reporters later that local security officers deemed the makeshift hospital unsafe.\\n\\n\"It seems that we\\'ve heard some reports in the international media that the United Nations asked or forced some medical teams to not work any more in some clinic -- that is not true, that is completely untrue,\" Mulet said Saturday.\\n\\nCNN video from the scene Friday night shows the Belgian team packing up its supplies and leaving with an escort of blue-helmeted U.N. peacekeepers in marked trucks.\\n\\nView or add to CNN\\'s database of missing persons in Haiti\\n\\nGupta -- assisted by other CNN staffers, security personnel and at least one Haitian nurse who refused to leave -- assessed the needs of the 25 patients, but there was little they could do without supplies.\\n\\nMore people, some in critical condition, were trickling in late Friday.\\n\\n\"I\\'ve never been in a situation like this. This is quite ridiculous,\" Gupta said.\\n\\nWith a dearth of medical facilities in Haiti\\'s capital, ambulances had nowhere else to take patients, some of whom had suffered severe trauma -- amputations and head injuries -- under the rubble. Others had suffered a great deal of blood loss, but there were no blood supplies left at the clinic.\\n\\nGupta feared that some would not survive the night.\\n\\nHe and the others stayed with the injured all night, after the medical team had left and after the generators gave out and the tents turned pitch black.\\n\\nGupta monitored patients\\' vital signs, administered painkillers and continued intravenous drips. He stabilized three new patients in critical condition.\\n\\nAt 3:45 a.m., he posted a message on Twitter: \"pulling all nighter at haiti field hosp. lots of work, but all patients stable. turned my crew into a crack med team tonight.\"\\n\\nAre you in Haiti and safe? Share your photos\\n\\nHe said the Belgian doctors did not want to leave their patients behind but were ordered out by the United Nations, which sent buses to transport them.\\n\\n\"There is concern about riots not far from here -- and this is part of the problem,\" Gupta said.\\n\\nThere have been scattered reports of violence throughout the capital.\\n\\n\"What is striking to me as a physician is that patients who just had surgery, patients who are critically ill, are essentially being left here, nobody to care for them,\" Gupta said.\\n\\nSandra Pierre, a Haitian who has been helping at the makeshift hospital, said the medical staff took most of the supplies with them.\\n\\n\"All the doctors, all the nurses are gone,\" she said. \"They are expected to be back tomorrow. They had no plan on leaving tonight. It was an order that came suddenly.\"\\n\\nShe told Gupta, \"It\\'s just you.\"\\n\\nA 7.0 magnitude earthquake flattened Haiti\\'s capital city Tuesday afternoon, affecting as many as 3 million people as it fanned out across the island nation. Tens of thousands of people are feared dead.\\n\\nHaiti, the poorest nation in the Western hemisphere, lacked adequate medical resources even before the disaster and has been struggling this week to tend to huge numbers of injured. The clinic, set up under several tents, was a godsend to the few who were lucky to have been brought there.\\n\\nRetired Army Lt. Gen. Russel Honore, who led relief efforts for Hurricane Katrina in 2005, said the evacuation of the clinic\\'s medical staff was unforgivable.\\n\\n\"Search and rescue must trump security,\" Honoré said. \"I\\'ve never seen anything like this before in my life. They need to man up and get back in there.\"\\n\\nHonoré drew parallels between the tragedy in New Orleans, Louisiana, and in Port-au-Prince. But even in the chaos of Katrina, he said, he had never seen medical staff walk away.\\n\\n\"I find this astonishing these doctors left,\" he said. \"People are scared of the poor.\"\\n\\nCNN\\'s Justine Redman, Danielle Dellorto and John Bonifield contributed to this report.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Skylion007/openwebtext dataset\n",
    "dataset = load_dataset('Skylion007/openwebtext')\n",
    "\n",
    "# Print the first example from the dataset\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 8013769\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"This is the bizarre moment an Asian woman praised Pauline Hanson by comparing her to both Donald Trump and Adolf Hitler.\\n\\nThe woman's gushing praise of the controversial One Nation leader was captured in an interview with ABC's The Link presenter Stan Grant.\\n\\nHe spoke to residents of New South Wales in a segment that aired on Friday night asking them what they think of Ms Hanson.\\n\\nWhile one man dismissed her as 'too anti-everything,' an Asian woman – who was not named – was filmed in a shopping centre as she heaped praise on Senator Hanson.\\n\\nThis woman heaped praise Pauline Hanson in an interview with The Link - comparing her to Donald Trump and Adolf Hitler\\n\\n'Pauline Hanson is straightforward,' she said.\\n\\n'She's sincere, she's not a hypocrite. If she doesn't like you, I don't like you.'\\n\\nThe woman continued to compliment Ms Hanson by comparing her qualities with two other nationalistic politicians she admires - the current President of the United States and the leader of Nazi Germany.\\n\\nSpeaking about why she likes Ms Hanson, the woman continued: 'Just like Trump. I like Trump. Donald Trump is sincere.\\n\\n'He's sincere, straightforward. If he tells you you're not okay, you're not okay – not okay for America. You're destroying our country.'\\n\\nThe unnamed woman described the One Nation leader as 'sincere' and 'straightforward'\\n\\nWhile some called Ms Hanson (pictured) 'too anti-everything', the woman continued to compliment her\\n\\nAsked if she would like to hear more Trump-inspired rhetoric in Australia, she replied: 'Yes, yes.'\\n\\nShe added: 'See like that speech he had yesterday, that was great. Yes, it sounded like Hitler, but you know, Hitler loved Germany.'\\n\\nLater on the programme, American political analyst and author Thomas Frank said the woman's comments were 'alarming'.\\n\\n'Oh my goodness, well, it sounds like you're going to get your own Donald Trump here soon,' he told Mr Grant.\\n\\n'That's a little bit alarming.\\n\\n'Everything those people said, you take out the accent and some of the slang and that's exactly the kind of thing you heard from Americans during the last election cycle.'\\n\\nThe woman compared Ms Hanson to other nationalistic politicians Donald Trump (pictured left) and Adolf Hitler (right)\\n\\nMs Hanson has said that Australians are calling out for a 'strong leader' like Vladimir Putin\\n\\nMeanwhile, Ms Hanson herself recently praised a controversial leader – Russian President Vladimir Putin.\\n\\nShe insisted that Australians are calling out for a 'strong leader' like Putin in an interview on Insiders.\\n\\n'I listened to a speech he gave in Parliament,' she told Insiders host Barrie Cassidy.\\n\\n'Even the people here in Australia were saying, 'I wish we had a leader like that here, I wish someone would stand up and fight for this country.'\\n\\n'That's what people expect.'\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the bizarre moment an Asian woman praised Pauline Hanson by comparing her to both Donald Trump and Adolf Hitler.\n",
      "\n",
      "The woman's gushing praise of the controversial One Nation leader was captured in an interview with ABC's The Link presenter Stan Grant.\n",
      "\n",
      "He spoke to residents of New South Wales in a segment that aired on Friday night asking them what they think of Ms Hanson.\n",
      "\n",
      "While one man dismissed her as 'too anti-everything,' an Asian woman – who was not named – was filmed in a shopping centre as she heaped praise on Senator Hanson.\n",
      "\n",
      "This woman heaped praise Pauline Hanson in an interview with The Link - comparing her to Donald Trump and Adolf Hitler\n",
      "\n",
      "'Pauline Hanson is straightforward,' she said.\n",
      "\n",
      "'She's sincere, she's not a hypocrite. If she doesn't like you, I don't like you.'\n",
      "\n",
      "The woman continued to compliment Ms Hanson by comparing her qualities with two other nationalistic politicians she admires - the current President of the United States and the leader of Nazi Germany.\n",
      "\n",
      "Speaking about why she likes Ms Hanson, the woman continued: 'Just like Trump. I like Trump. Donald Trump is sincere.\n",
      "\n",
      "'He's sincere, straightforward. If he tells you you're not okay, you're not okay – not okay for America. You're destroying our country.'\n",
      "\n",
      "The unnamed woman described the One Nation leader as 'sincere' and 'straightforward'\n",
      "\n",
      "While some called Ms Hanson (pictured) 'too anti-everything', the woman continued to compliment her\n",
      "\n",
      "Asked if she would like to hear more Trump-inspired rhetoric in Australia, she replied: 'Yes, yes.'\n",
      "\n",
      "She added: 'See like that speech he had yesterday, that was great. Yes, it sounded like Hitler, but you know, Hitler loved Germany.'\n",
      "\n",
      "Later on the programme, American political analyst and author Thomas Frank said the woman's comments were 'alarming'.\n",
      "\n",
      "'Oh my goodness, well, it sounds like you're going to get your own Donald Trump here soon,' he told Mr Grant.\n",
      "\n",
      "'That's a little bit alarming.\n",
      "\n",
      "'Everything those people said, you take out the accent and some of the slang and that's exactly the kind of thing you heard from Americans during the last election cycle.'\n",
      "\n",
      "The woman compared Ms Hanson to other nationalistic politicians Donald Trump (pictured left) and Adolf Hitler (right)\n",
      "\n",
      "Ms Hanson has said that Australians are calling out for a 'strong leader' like Vladimir Putin\n",
      "\n",
      "Meanwhile, Ms Hanson herself recently praised a controversial leader – Russian President Vladimir Putin.\n",
      "\n",
      "She insisted that Australians are calling out for a 'strong leader' like Putin in an interview on Insiders.\n",
      "\n",
      "'I listened to a speech he gave in Parliament,' she told Insiders host Barrie Cassidy.\n",
      "\n",
      "'Even the people here in Australia were saying, 'I wish we had a leader like that here, I wish someone would stand up and fight for this country.'\n",
      "\n",
      "'That's what people expect.'\n"
     ]
    }
   ],
   "source": [
    "example = dataset['train'][222]\n",
    "print(example['text'])\n",
    "tokens = model.to_tokens(example['text'], prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 631])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache_with_saes(tokens, saes=sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([631, 24576])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_acts = cache['blocks.7.hook_resid_pre.hook_sae_acts_post']\n",
    "live_feature = sae_acts > 0\n",
    "live_feature_union = live_feature.any(dim=0)\n",
    "live_feature_union.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24576/24576 [00:12<00:00, 2013.18it/s]\n"
     ]
    }
   ],
   "source": [
    "sim = cosine_similarity_by_column(live_feature_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(495.)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_sim = torch.sum(sim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24576])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24576])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live_feature_union.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(495, device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = live_feature_union.sum(0)\n",
    "torch.max(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm.tqdm(range(len(dataset['train']))):\n",
    "    #for idx in tqdm.tqdm(range(10)):\n",
    "    example = dataset['train'][idx]\n",
    "    tokens = model.to_tokens(example['text'], prepend_bos=True)\n",
    "    _, cache = model.run_with_cache_with_saes(tokens, saes=sae)\n",
    "    sae_acts = cache['blocks.7.hook_resid_pre.hook_sae_acts_post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 31/8013769 [00:07<540:22:43,  4.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# live_feature = sae_acts > 0\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# live_feature_union = live_feature.any(dim=0)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m seq_sim \u001b[38;5;241m=\u001b[39m sae_acts\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_sim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/code/sae/SAE_Geometry/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:546\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_imports\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/code/sae/SAE_Geometry/.venv/lib/python3.12/site-packages/numpy/lib/format.py:730\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 730\u001b[0m         \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[1;32m    733\u001b[0m                 array, flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternal_loop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    734\u001b[0m                 buffersize\u001b[38;5;241m=\u001b[39mbuffersize, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open(\"activation.npy\", \"wb\") as f:\n",
    "    for idx in tqdm.tqdm(range(len(dataset['train']))):\n",
    "    #for idx in tqdm.tqdm(range(10)):\n",
    "        example = dataset['train'][idx]\n",
    "        tokens = model.to_tokens(example['text'], prepend_bos=True)\n",
    "        _, cache = model.run_with_cache_with_saes(tokens, saes=sae)\n",
    "        sae_acts = cache['blocks.7.hook_resid_pre.hook_sae_acts_post']\n",
    "        # live_feature = sae_acts > 0\n",
    "        # live_feature_union = live_feature.any(dim=0)\n",
    "        seq_sim = sae_acts.sum(0)\n",
    "        np.save(f, seq_sim.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  11   0 ...  18 164   4]\n",
      "[  0  14   0 ...  53 157  20]\n"
     ]
    }
   ],
   "source": [
    "with open('activation.npy', 'rb') as f:\n",
    "    activation1 = np.load(f)\n",
    "    activation2 = np.load(f)\n",
    "print(activation2)\n",
    "print(activation1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.npy', 'wb') as f:\n",
    "    np.save(f, np.array([1, 2]))\n",
    "    np.save(f, np.array([1, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[1 3]\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "No data left in file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mload(f))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mload(f))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/mnt/d/code/sae/SAE_Geometry/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:436\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    434\u001b[0m magic \u001b[38;5;241m=\u001b[39m fid\u001b[38;5;241m.\u001b[39mread(N)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m magic:\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data left in file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# If the file size is less than N, we need to make sure not\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# to seek past the beginning of the file\u001b[39;00m\n\u001b[1;32m    439\u001b[0m fid\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m(N, \u001b[38;5;28mlen\u001b[39m(magic)), \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# back-up\u001b[39;00m\n",
      "\u001b[0;31mEOFError\u001b[0m: No data left in file"
     ]
    }
   ],
   "source": [
    "with open('test.npy', 'rb') as f:\n",
    "    print(np.load(f))\n",
    "    print(np.load(f))\n",
    "    print(np.load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
